{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":1103067,"sourceType":"datasetVersion","datasetId":561256}],"dockerImageVersionId":30191,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Setup the Environment**","metadata":{}},{"cell_type":"code","source":"!pip install nilearn==0.5.2 niwidgets==0.2.2 numpy-stl==2.11.2\n!pip install open3d k3d\n!pip3 install ipympl","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**After succesful installation, restart and clear cell outputs.**\nComment the above lines, hit run all","metadata":{}},{"cell_type":"markdown","source":"# **Import all dependencies**","metadata":{}},{"cell_type":"code","source":"import os, glob\nimport nibabel as nib\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport cv2\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator \nfrom tensorflow.keras.models import load_model\nfrom tensorflow import keras\nimport shutil, pathlib, fnmatch\nimport PIL\nfrom niwidgets import NiftiWidget\nimport numpy as np\nimport open3d as o3d\nfrom mpl_toolkits.mplot3d import Axes3D\nimport matplotlib.pyplot as plt\nfrom skimage import measure\nfrom stl import mesh\nfrom sklearn.metrics import confusion_matrix","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Pre-processing**","metadata":{}},{"cell_type":"code","source":"# Load image and see max min Hounsfield units\nimgPath = os.path.join(imagePathInput, \"coronacases_org_002.nii\")\nimg = nib.load(imgPath).get_fdata()\nnp.min(img), np.max(img), img.shape, type(img)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# CONSTANTS!!!\n\n# STEP 1 - Load and visualize data\ndataInputPath = '../input/covid19-ct-scans'\nimagePathInput = os.path.join(dataInputPath, 'ct_scans/')\nmaskPathInput = os.path.join(dataInputPath, 'infection_mask/')\n\ndataOutputPath = './slices/'\nimageSliceOutput = os.path.join(dataOutputPath, 'img/')\nmaskSliceOutput = os.path.join(dataOutputPath, 'mask/')\nos.makedirs(imageSliceOutput,mode = 0o666)\nos.makedirs(maskSliceOutput,mode = 0o666)\n# STEP 2 - Image normalization\nHOUNSFIELD_MIN = -1000\nHOUNSFIELD_MAX = 2000\nHOUNSFIELD_RANGE = HOUNSFIELD_MAX - HOUNSFIELD_MIN\n\n# STEP 3 - Slicing and saving\nSLICE_X = True\nSLICE_Y = True\nSLICE_Z = True\n\nSLICE_DECIMATE_IDENTIFIER = 3","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load image mask and see max min Hounsfield units\nmaskPath = os.path.join(maskPathInput, \"coronacases_002.nii\")\nmask = nib.load(maskPath).get_fdata()\nnp.min(mask), np.max(mask), mask.shape, type(mask)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Show image slice\nimgSlice = mask[150,:,:]\nplt.imshow(imgSlice, cmap='gray')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Normalize image\ndef normalizeImageIntensityRange(img):\n    img[img < HOUNSFIELD_MIN] = HOUNSFIELD_MIN\n    img[img > HOUNSFIELD_MAX] = HOUNSFIELD_MAX\n    return (img - HOUNSFIELD_MIN) / HOUNSFIELD_RANGE\n\nnImg = normalizeImageIntensityRange(img)\nnp.min(nImg), np.max(nImg), nImg.shape, type(nImg)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Read image or mask volume\ndef readImageVolume(imgPath, normalize=False):\n    img = nib.load(imgPath).get_fdata()\n    if normalize:\n        return normalizeImageIntensityRange(img)\n    else:\n        return img\n    \nreadImageVolume(imgPath, normalize=True)\nreadImageVolume(maskPath, normalize=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Save volume slice to file\ndef saveSlice(img, fname, path):\n    print(\"image shape:\",img.shape) \n    img = np.uint8(img * 255)\n    fout = os.path.join(path, f'{fname}.png')\n    cv2.imwrite(fout, img)\n    print(f'[+] Slice saved: {fout}', end='\\r')\n    \n# saveSlice(nImg[20,:,:], 'test', imageSliceOutput)\n# saveSlice(mask[20,:,:], 'test', maskSliceOutput)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Slice image in all directions and save\ndef sliceAndSaveVolumeImage(vol, fname, path):\n    (dimx, dimy, dimz) = vol.shape\n    print(dimx, dimy, dimz)\n    cnt = 0\n    if SLICE_X:\n        cnt += dimx\n        print('Slicing X: ')\n        for i in range(dimx):\n            saveSlice(vol[i,:,:], fname+f'-slice{str(i).zfill(SLICE_DECIMATE_IDENTIFIER)}_x', path)\n            \n    if SLICE_Y:\n        cnt += dimy\n        print('Slicing Y: ')\n        for i in range(dimy):\n            saveSlice(vol[:,i,:], fname+f'-slice{str(i).zfill(SLICE_DECIMATE_IDENTIFIER)}_y', path)\n            \n    if SLICE_Z:\n        cnt += dimz\n        print('Slicing Z: ')\n        for i in range(dimz):\n            saveSlice(vol[:,:,i], fname+f'-slice{str(i).zfill(SLICE_DECIMATE_IDENTIFIER)}_z', path)\n    return cnt","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Read and process image volumes\nfor index, filename in enumerate(sorted(glob.iglob(imagePathInput+'coronacases*.nii'))):\n    img = readImageVolume(filename, True)\n    print(filename, img.shape, np.sum(img.shape), np.min(img), np.max(img))\n    numOfSlices = sliceAndSaveVolumeImage(img, 'lungs'+str(index), imageSliceOutput)\n    print(f'\\n{filename}, {numOfSlices} slices created \\n')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Read and process image mask volumes\nfor index, filename in enumerate(sorted(glob.iglob(maskPathInput+'coronacases*.nii'))):\n    img = readImageVolume(filename, False)\n    print(filename, img.shape, np.sum(img.shape), np.min(img), np.max(img))\n    numOfSlices = sliceAndSaveVolumeImage(img, 'lungs'+str(index), maskSliceOutput)\n    print(f'\\n{filename}, {numOfSlices} slices created \\n')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"count=0\nfor filename in os.listdir(\"./slices/mask\"):\n    count+=1\ncount*2","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Lung Segmentation using U-net**","metadata":{}},{"cell_type":"markdown","source":"Organizing data in appropriate train & test folders","metadata":{}},{"cell_type":"code","source":"dataPath = './'\ntraindataSliceOutput = os.path.join(dataPath, 'training/img/img/')\ntrainmaskSliceOutput = os.path.join(dataPath, 'training/mask/mask/')\ntestdataSliceOutput = os.path.join(dataPath, 'test/img/img/')\ntestmaskSliceOutput = os.path.join(dataPath, 'test/mask/mask/')\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#function to move data from source to destination using string regex\ndef move_dir(src: str, dst: str, pattern: str = '*'):\n    if not os.path.isdir(dst):\n        pathlib.Path(dst).mkdir(parents=True, exist_ok=True)\n    for f in fnmatch.filter(os.listdir(src), pattern):\n        shutil.move(os.path.join(src, f), os.path.join(dst, f))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os.makedirs(traindataSliceOutput,mode = 0o666)\nos.makedirs(trainmaskSliceOutput,mode = 0o666)\nos.makedirs(testdataSliceOutput,mode = 0o666)\nos.makedirs(testmaskSliceOutput,mode = 0o666)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Uncomment if more test samples are required. Currently using 2 test, 8 train.","metadata":{}},{"cell_type":"code","source":"# move_dir(imageSliceOutput,testdataSliceOutput,'lungs6*.png')\n# move_dir(imageSliceOutput,testdataSliceOutput,'lungs7*.png')\nmove_dir(imageSliceOutput,testdataSliceOutput,'lungs8*.png')\nmove_dir(imageSliceOutput,testdataSliceOutput,'lungs9*.png')\n# move_dir(maskSliceOutput,testmaskSliceOutput,'lungs6*.png')\n# move_dir(maskSliceOutput,testmaskSliceOutput,'lungs7*.png')\nmove_dir(maskSliceOutput,testmaskSliceOutput,'lungs8*.png')\nmove_dir(maskSliceOutput,testmaskSliceOutput,'lungs9*.png')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Move the remaining files into training data folder\nmove_dir(imageSliceOutput,traindataSliceOutput,'*.png')\nmove_dir(maskSliceOutput,trainmaskSliceOutput,'*.png')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define constants\nSEED = 909\nBATCH_SIZE_TRAIN = 16\nBATCH_SIZE_TEST = 16\n\nIMAGE_HEIGHT = 512\nIMAGE_WIDTH = 256\nIMG_SIZE = (IMAGE_HEIGHT, IMAGE_WIDTH)\n\ndata_dir = './'\ndata_dir_train = os.path.join(data_dir, 'training')\n# The images should be stored under: \"data/slices/training/img/img\"\ndata_dir_train_image = os.path.join(data_dir_train, 'img')\n# The images should be stored under: \"data/slices/training/mask/img\"\ndata_dir_train_mask = os.path.join(data_dir_train, 'mask')\n\ndata_dir_test = os.path.join(data_dir, 'test')\n# The images should be stored under: \"data/slices/test/img/img\"\ndata_dir_test_image = os.path.join(data_dir_test, 'img')\n# The images should be stored under: \"data/slices/test/mask/img\"\ndata_dir_test_mask = os.path.join(data_dir_test, 'mask')\n\nNUM_TRAIN = len(os.listdir(traindataSliceOutput))\nNUM_TEST = len(os.listdir(testdataSliceOutput))\n\nNUM_OF_EPOCHS = 5","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Folder structure organization done! Create Data generators for training.","metadata":{}},{"cell_type":"code","source":"#Uncomment below lines, if Data augmentation during training is required.\ndef create_segmentation_generator_train(img_path, msk_path, BATCH_SIZE):\n    data_gen_args = dict(rescale=1./255\n#                      featurewise_center=True,\n#                      featurewise_std_normalization=True,\n#                      rotation_range=90\n#                      width_shift_range=0.2,\n#                      height_shift_range=0.2,\n#                      zoom_range=0.3\n                        )\n    datagen = ImageDataGenerator(**data_gen_args)\n    \n    img_generator = datagen.flow_from_directory(img_path, target_size=IMG_SIZE, class_mode=None, color_mode='grayscale', batch_size=BATCH_SIZE, seed=SEED)\n    msk_generator = datagen.flow_from_directory(msk_path, target_size=IMG_SIZE, class_mode=None, color_mode='grayscale', batch_size=BATCH_SIZE, seed=SEED)\n    return zip(img_generator, msk_generator)\n\n# Remember not to perform any image augmentation in the test generator!\ndef create_segmentation_generator_test(img_path, msk_path, BATCH_SIZE):\n    data_gen_args = dict(rescale=1./255)\n    datagen = ImageDataGenerator(**data_gen_args)\n    \n    img_generator = datagen.flow_from_directory(img_path, target_size=IMG_SIZE, class_mode=None, color_mode='grayscale', batch_size=BATCH_SIZE, seed=SEED)\n    msk_generator = datagen.flow_from_directory(msk_path, target_size=IMG_SIZE, class_mode=None, color_mode='grayscale', batch_size=BATCH_SIZE, seed=SEED)\n    return zip(img_generator, msk_generator)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_generator = create_segmentation_generator_train(data_dir_train_image, data_dir_train_mask, BATCH_SIZE_TRAIN)\ntest_generator = create_segmentation_generator_test(data_dir_test_image, data_dir_test_mask, BATCH_SIZE_TEST)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Function to compare between input, mask and prediction\ndef display(display_list):\n    plt.figure(figsize=(15,15))\n    \n    title = ['Input Image', 'True Mask', 'Predicted Mask']\n    \n    for i in range(len(display_list)):\n        plt.subplot(1, len(display_list), i+1)\n        plt.title(title[i])\n        plt.imshow(tf.keras.preprocessing.image.array_to_img(display_list[i]), cmap='gray')\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Function to display top n images in datagen\ndef show_dataset(datagen, num=1):\n    for i in range(0,num):\n        image,mask = next(datagen)\n        display([image[0], mask[0]])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Visualize top 3 image comparisons in datagen\nshow_dataset(train_generator, 3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"U-net model development","metadata":{}},{"cell_type":"code","source":"def unet(n_levels, initial_features=32, n_blocks=2, kernel_size=3, pooling_size=2, in_channels=1, out_channels=1):\n    inputs = keras.layers.Input(shape=(IMAGE_HEIGHT, IMAGE_WIDTH, in_channels))\n    x = inputs\n    \n    convpars = dict(kernel_size=kernel_size, activation='relu', padding='same')\n    \n    #downstream\n    skips = {}\n    for level in range(n_levels):\n        for _ in range(n_blocks):\n            x = keras.layers.Conv2D(initial_features * 2 ** level, **convpars)(x)\n        if level < n_levels - 1:\n            skips[level] = x\n            x = keras.layers.MaxPool2D(pooling_size)(x)\n            \n    # upstream\n    for level in reversed(range(n_levels-1)):\n        x = keras.layers.Conv2DTranspose(initial_features * 2 ** level, strides=pooling_size, **convpars)(x)\n        x = keras.layers.Concatenate()([x, skips[level]])\n        for _ in range(n_blocks):\n            x = keras.layers.Conv2D(initial_features * 2 ** level, **convpars)(x)\n            \n    # output\n    activation = 'sigmoid' if out_channels == 1 else 'softmax'\n    x = keras.layers.Conv2D(out_channels, kernel_size=1, activation=activation, padding='same')(x)\n    \n    return keras.Model(inputs=[inputs], outputs=[x], name=f'UNET-L{n_levels}-F{initial_features}')\n        ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"EPOCH_STEP_TRAIN = NUM_TRAIN // BATCH_SIZE_TRAIN\nEPOCH_STEP_TEST = NUM_TEST // BATCH_SIZE_TEST\n#Instantiate U-net with 4 levels\nmodel = unet(4)\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.fit_generator(generator=train_generator, \n                    steps_per_epoch=EPOCH_STEP_TRAIN, \n                    validation_data=test_generator, \n                    validation_steps=EPOCH_STEP_TEST,\n                   epochs=NUM_OF_EPOCHS)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save(f'UNET-LungSegmentation_{IMAGE_HEIGHT}_{IMAGE_WIDTH}.h5')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_generator = create_segmentation_generator_test(data_dir_test_image, data_dir_test_mask, 1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def show_prediction(datagen, num=1):\n    for i in range(0,num):\n        image,mask = next(datagen)\n        pred_mask = model.predict(image)[0] > 0.5\n        display([image[0], mask[0], pred_mask])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"show_prediction(test_generator, 3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **3D mesh generation**","metadata":{}},{"cell_type":"code","source":"#normalization. All constants have been defined above\ndef normalizeImageIntensityRange(img):\n    img[img < HOUNSFIELD_MIN] = HOUNSFIELD_MIN\n    img[img > HOUNSFIELD_MAX] = HOUNSFIELD_MAX\n    return (img - HOUNSFIELD_MIN)/HOUNSFIELD_RANGE","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Linear interpolation to target width & height\ndef scaleImg(img, height, width):\n    return cv2.resize(img, dsize=(width, height), interpolation=cv2.INTER_LINEAR)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sliceIndex = 100","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Load a sample test case, inference it and visualize","metadata":{}},{"cell_type":"code","source":"targetImagePath = f'../input/covid19-ct-scans/ct_scans/coronacases_org_010.nii'\ntargetMaskPath  = f'../input/covid19-ct-scans/infection_mask/coronacases_010.nii'\n\nimgTargetNii = nib.load(targetImagePath)\nimgMaskNii = nib.load(targetMaskPath)\n\nimgTarget = normalizeImageIntensityRange(imgTargetNii.get_fdata())\nimgMask = imgMaskNii.get_fdata()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# show input image slice\nplt.figure(figsize=(15,15))\nimgSlice = imgTarget[sliceIndex,:,:]\nimgDimX, imgDimY = imgSlice.shape\nimgSliceScaled = scaleImg(imgSlice, IMAGE_HEIGHT, IMAGE_WIDTH)\nplt.subplot(1,2,1)\nplt.imshow(imgSlice, cmap='gray')\nplt.subplot(1,2,2)\nplt.imshow(imgSliceScaled, cmap='gray')\nplt.show()\nimgSlice.shape, imgSliceScaled.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# show input mask slice\nplt.figure(figsize=(15,15))\nmaskSlice = imgMask[sliceIndex,:,:]\nmaskSliceScaled = scaleImg(maskSlice, IMAGE_HEIGHT, IMAGE_WIDTH)\nplt.subplot(1,2,1)\nplt.imshow(maskSlice, cmap='gray')\nplt.subplot(1,2,2)\nplt.imshow(maskSliceScaled, cmap='gray')\nplt.show()\nmaskSlice.shape, maskSliceScaled.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Predict with UNET model\nplt.figure(figsize=(15,15))\nimageInput = imgSliceScaled[np.newaxis,:,:,np.newaxis]\nmaskPredict = model.predict(imageInput)[0,:,:,0]\nmaskPredictScaled = scaleImg(maskPredict, imgDimX, imgDimY)\nplt.subplot(1,2,2)\nplt.imshow(maskPredict, cmap='gray')\nplt.subplot(1,2,1)\nplt.imshow(maskPredictScaled, cmap='gray')\nplt.show()\nmaskPredictScaled.shape, maskPredict.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def predictVolume(inImg, toBin=True):\n    (xMax, yMax, zMax) = inImg.shape\n    \n    outImgX = np.zeros((xMax, yMax, zMax))\n    outImgY = np.zeros((xMax, yMax, zMax))\n    outImgZ = np.zeros((xMax, yMax, zMax))\n    \n    cnt = 0.0\n    if SLICE_X:\n        cnt += 1.0\n        for i in range(xMax):\n            img = scaleImg(inImg[i,:,:], IMAGE_HEIGHT, IMAGE_WIDTH)[np.newaxis,:,:,np.newaxis]\n            tmp = model.predict(img)[0,:,:,0]\n            outImgX[i,:,:] = scaleImg(tmp, yMax, zMax)\n    if SLICE_Y:\n        cnt += 1.0\n        for i in range(yMax):\n            img = scaleImg(inImg[:,i,:], IMAGE_HEIGHT, IMAGE_WIDTH)[np.newaxis,:,:,np.newaxis]\n            tmp = model.predict(img)[0,:,:,0]\n            outImgY[:,i,:] = scaleImg(tmp, xMax, zMax)\n    if SLICE_Z:\n        cnt += 1.0\n        for i in range(zMax):\n            img = scaleImg(inImg[:,:,i], IMAGE_HEIGHT, IMAGE_WIDTH)[np.newaxis,:,:,np.newaxis]\n            tmp = model.predict(img)[0,:,:,0]\n            outImgZ[:,:,i] = scaleImg(tmp, xMax, yMax)\n            \n    outImg = (outImgX + outImgY + outImgZ)/cnt\n    if(toBin):\n        outImg[outImg>0.5] = 1.0\n        outImg[outImg<=0.5] = 0.0\n    return outImg","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predImg = predictVolume(imgTarget)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Visualize Input image","metadata":{}},{"cell_type":"code","source":"my_widget = NiftiWidget(imgTargetNii)\nmy_widget.nifti_plotter(colormap='gray')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Visualize Predicted/inferenced mask","metadata":{}},{"cell_type":"code","source":"my_widget = NiftiWidget(nib.dataobj_images.DataobjImage(predImg))\nmy_widget.nifti_plotter(colormap='gray')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Visualize annotated mask","metadata":{}},{"cell_type":"code","source":"my_widget = NiftiWidget(imgMaskNii)\nmy_widget.nifti_plotter(colormap='gray')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vertices,faces,_,_ = measure.marching_cubes(predImg) #inference mask\nctvertices,ctfaces,ct,ct=measure.marching_cubes(imgTarget) #input scan \nmaskvertices,maskfaces,mk,mk=measure.marching_cubes(imgMask) #annotated mask","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Convert vertices and faces to mesh ","metadata":{}},{"cell_type":"code","source":"def dataToMesh(vert, faces):\n    mm = mesh.Mesh(np.zeros(faces.shape[0], dtype=mesh.Mesh.dtype))\n    for i, f in enumerate(faces):\n        for j in range(3):\n            mm.vectors[i][j] = vert[f[j],:]\n    return mm","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Save all .stl mesh files","metadata":{}},{"cell_type":"code","source":"mm = dataToMesh(vertices, faces)\nmm.save('./Inferenced_lung_010.stl')\nmm = dataToMesh(ctvertices, ctfaces)\nmm.save('./Input_lung_010.stl')\nmm = dataToMesh(maskvertices, maskfaces)\nmm.save('./Mask_lung_010.stl')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Metrics**","metadata":{}},{"cell_type":"code","source":"def confusion_matrix_gen(y_true,y_pred):\n    y_true=y_true.flatten()\n    y_pred=y_pred.flatten()\n    y_true[y_true>0.5]=1.0\n    y_pred[y_pred>0.5]=1.0\n    tn, fp, fn, tp=confusion_matrix(y_true, y_pred).ravel()\n    return (tn,fp,fn,tp)\n\ndef accuracy(TN, FP, FN, TP):\n    return (TP+TN)/(TN+FP+FN+TP)\n\ndef precision(TN, FP, FN, TP):\n    return TP/(TP+FP)\n\ndef recall(TN, FP, FN, TP):\n    return TP/(TP+FN)\n\ndef dsc(TN, FP, FN, TP):\n    return (2*TP)/((2*TP)+FP+FN)\n\ndef jsi(TN, FP, FN, TP):\n    return TP/(TP+FP+FN)\n\ndef f1_score(TN, FP, FN, TP):\n    precision=TP/(TP+FP)\n    recall=TP/(TP+FN)\n    return 2*(precision*recall)/(precision+recall)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"testset=[\"009\",\"010\"]\nTN, FP, FN, TP = 0, 0, 0, 0\nfor i in testset:\n    targetImagePath = f'../input/covid19-ct-scans/ct_scans/coronacases_org_{}.nii'.format(i)\n    targetMaskPath  = f'../input/covid19-ct-scans/infection_mask/coronacases_{}.nii'.format(i)\n\n    imgTargetNii = nib.load(targetImagePath)\n    imgMaskNii = nib.load(targetMaskPath)\n\n    imgTarget = normalizeImageIntensityRange(imgTargetNii.get_fdata())\n    imgMask = imgMaskNii.get_fdata()\n    \n    predImg = predictVolume(imgTarget)\n    tn, fp, fn, tp = confusion_matrix_gen(imgMask,predImg)\n    TN+=tn\n    FP+=fp\n    FN+=fn\n    TP+=tp\n    \nprint(\"acuracy:\",accuracy(TN, FP, FN, TP))\nprint(\"precision:\",precision(TN, FP, FN, TP))\nprint(\"recall:\",recall(TN, FP, FN, TP))\nprint(\"dsc:\",dsc(TN, FP, FN, TP))\nprint(\"jsi:\",jsi(TN, FP, FN, TP))\nprint(\"f1_score:\",f1_score(TN, FP, FN, TP))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Point cloud generation**","metadata":{}},{"cell_type":"code","source":"mesh = o3d.io.read_triangle_mesh(\"./Inferenced_lung_010.stl\")\nprint(\"_\")\npointcloud = mesh.sample_points_poisson_disk(100000)\nxyz_load = np.asarray(pointcloud.points,dtype=np.float32)\nprint('xyz_load shape', xyz_load.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%matplotlib widget\n\nfig = plt.figure()\nax = Axes3D(fig)\n  \n# creating the plot\nplot_geeks = ax.scatter(xyz_load[:10000,0], xyz_load[:10000,1], xyz_load[:10000,2], color='green')\n  \n# setting title and labels\nax.set_title(\"3D plot\")\nax.set_xlabel('x-axis')\nax.set_ylabel('y-axis')\nax.set_zlabel('z-axis')\n  \n# displaying the plot\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure()\nax = plt.axes(projection =\"3d\")\nax.scatter3D(xyz_load[:,0], xyz_load[:,1], xyz_load[:,2], color = \"green\")\nplt.title(\"simple 3D scatter plot\")\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with open('Inferenced_lung_010_pcd.xyz', 'w') as f:\n    for line in xyz_load:\n        f.write(\"{}\\t {}\\t {}\\t\".format(str(line[0]),str(line[1]),str(line[2])))\n        f.write('\\n')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"One-time pcd loop generation","metadata":{}},{"cell_type":"code","source":"for filename in sorted(glob.iglob(\"./\" + '*.stl')):\n    mesh = o3d.io.read_triangle_mesh(filename)\n    print(\"Mesh read complete\")\n    pointcloud = mesh.sample_points_poisson_disk(100000)\n    print(\"PCD generation complete\")\n    xyz_load = np.asarray(pointcloud.points,dtype=np.float32)\n    print('xyz_load shape', xyz_load.shape)\n    with open('{}_pcd.xyz'.format(filename[:-4]), 'w') as f:\n        for line in xyz_load:\n            f.write(\"{}\\t {}\\t {}\\t\".format(str(line[0]),str(line[1]),str(line[2])))\n            f.write('\\n')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}
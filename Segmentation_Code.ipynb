{"cells":[{"cell_type":"markdown","metadata":{},"source":["# **Setup the Environment**"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"outputs":[],"source":["!pip install nilearn==0.5.2 niwidgets==0.2.2 numpy-stl==2.11.2\n","!pip install open3d k3d\n","!pip3 install ipympl"]},{"cell_type":"markdown","metadata":{},"source":["**After succesful installation, restart and clear cell outputs.**\n","Comment the above lines, hit run all"]},{"cell_type":"markdown","metadata":{},"source":["# **Import all dependencies**"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import os, glob\n","import nibabel as nib\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import cv2\n","import tensorflow as tf\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator \n","from tensorflow.keras.models import load_model\n","from tensorflow import keras\n","import shutil, pathlib, fnmatch\n","import PIL\n","from niwidgets import NiftiWidget\n","import numpy as np\n","import open3d as o3d\n","from mpl_toolkits.mplot3d import Axes3D\n","import matplotlib.pyplot as plt\n","from skimage import measure\n","from stl import mesh\n","from sklearn.metrics import confusion_matrix"]},{"cell_type":"markdown","metadata":{},"source":["# **Pre-processing**"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# CONSTANTS!!!\n","\n","# STEP 1 - Load and visualize data\n","dataInputPath = '../input/covid19-ct-scans'\n","imagePathInput = os.path.join(dataInputPath, 'ct_scans/')\n","maskPathInput = os.path.join(dataInputPath, 'infection_mask/')\n","\n","dataOutputPath = './slices/'\n","imageSliceOutput = os.path.join(dataOutputPath, 'img/')\n","maskSliceOutput = os.path.join(dataOutputPath, 'mask/')\n","os.makedirs(imageSliceOutput,mode = 0o666)\n","os.makedirs(maskSliceOutput,mode = 0o666)\n","# STEP 2 - Image normalization\n","HOUNSFIELD_MIN = -1000\n","HOUNSFIELD_MAX = 2000\n","HOUNSFIELD_RANGE = HOUNSFIELD_MAX - HOUNSFIELD_MIN\n","\n","# STEP 3 - Slicing and saving\n","SLICE_X = True\n","SLICE_Y = True\n","SLICE_Z = True\n","\n","SLICE_DECIMATE_IDENTIFIER = 3"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Load image and see max min Hounsfield units\n","imgPath = os.path.join(imagePathInput, \"coronacases_org_002.nii\")\n","img = nib.load(imgPath).get_fdata()\n","np.min(img), np.max(img), img.shape, type(img)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Load image mask and see max min Hounsfield units\n","maskPath = os.path.join(maskPathInput, \"coronacases_002.nii\")\n","mask = nib.load(maskPath).get_fdata()\n","np.min(mask), np.max(mask), mask.shape, type(mask)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Show image slice\n","imgSlice = mask[150,:,:]\n","plt.imshow(imgSlice, cmap='gray')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Normalize image\n","def normalizeImageIntensityRange(img):\n","    img[img < HOUNSFIELD_MIN] = HOUNSFIELD_MIN\n","    img[img > HOUNSFIELD_MAX] = HOUNSFIELD_MAX\n","    return (img - HOUNSFIELD_MIN) / HOUNSFIELD_RANGE\n","\n","nImg = normalizeImageIntensityRange(img)\n","np.min(nImg), np.max(nImg), nImg.shape, type(nImg)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Read image or mask volume\n","def readImageVolume(imgPath, normalize=False):\n","    img = nib.load(imgPath).get_fdata()\n","    if normalize:\n","        return normalizeImageIntensityRange(img)\n","    else:\n","        return img\n","    \n","readImageVolume(imgPath, normalize=True)\n","readImageVolume(maskPath, normalize=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Save volume slice to file\n","def saveSlice(img, fname, path):\n","    print(\"image shape:\",img.shape) \n","    img = np.uint8(img * 255)\n","    fout = os.path.join(path, f'{fname}.png')\n","    cv2.imwrite(fout, img)\n","    print(f'[+] Slice saved: {fout}', end='\\r')\n","    \n","# saveSlice(nImg[20,:,:], 'test', imageSliceOutput)\n","# saveSlice(mask[20,:,:], 'test', maskSliceOutput)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Slice image in all directions and save\n","def sliceAndSaveVolumeImage(vol, fname, path):\n","    (dimx, dimy, dimz) = vol.shape\n","    print(dimx, dimy, dimz)\n","    cnt = 0\n","    if SLICE_X:\n","        cnt += dimx\n","        print('Slicing X: ')\n","        for i in range(dimx):\n","            saveSlice(vol[i,:,:], fname+f'-slice{str(i).zfill(SLICE_DECIMATE_IDENTIFIER)}_x', path)\n","            \n","    if SLICE_Y:\n","        cnt += dimy\n","        print('Slicing Y: ')\n","        for i in range(dimy):\n","            saveSlice(vol[:,i,:], fname+f'-slice{str(i).zfill(SLICE_DECIMATE_IDENTIFIER)}_y', path)\n","            \n","    if SLICE_Z:\n","        cnt += dimz\n","        print('Slicing Z: ')\n","        for i in range(dimz):\n","            saveSlice(vol[:,:,i], fname+f'-slice{str(i).zfill(SLICE_DECIMATE_IDENTIFIER)}_z', path)\n","    return cnt"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Read and process image volumes\n","for index, filename in enumerate(sorted(glob.iglob(imagePathInput+'coronacases*.nii'))):\n","    img = readImageVolume(filename, True)\n","    print(filename, img.shape, np.sum(img.shape), np.min(img), np.max(img))\n","    numOfSlices = sliceAndSaveVolumeImage(img, 'lungs'+str(index), imageSliceOutput)\n","    print(f'\\n{filename}, {numOfSlices} slices created \\n')"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Read and process image mask volumes\n","for index, filename in enumerate(sorted(glob.iglob(maskPathInput+'coronacases*.nii'))):\n","    img = readImageVolume(filename, False)\n","    print(filename, img.shape, np.sum(img.shape), np.min(img), np.max(img))\n","    numOfSlices = sliceAndSaveVolumeImage(img, 'lungs'+str(index), maskSliceOutput)\n","    print(f'\\n{filename}, {numOfSlices} slices created \\n')"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["count=0\n","for filename in os.listdir(\"./slices/mask\"):\n","    count+=1\n","count*2"]},{"cell_type":"markdown","metadata":{},"source":["# **Lung Segmentation using U-net**"]},{"cell_type":"markdown","metadata":{},"source":["Organizing data in appropriate train & test folders"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["dataPath = './'\n","traindataSliceOutput = os.path.join(dataPath, 'training/img/img/')\n","trainmaskSliceOutput = os.path.join(dataPath, 'training/mask/mask/')\n","testdataSliceOutput = os.path.join(dataPath, 'test/img/img/')\n","testmaskSliceOutput = os.path.join(dataPath, 'test/mask/mask/')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["#function to move data from source to destination using string regex\n","def move_dir(src: str, dst: str, pattern: str = '*'):\n","    if not os.path.isdir(dst):\n","        pathlib.Path(dst).mkdir(parents=True, exist_ok=True)\n","    for f in fnmatch.filter(os.listdir(src), pattern):\n","        shutil.move(os.path.join(src, f), os.path.join(dst, f))"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["os.makedirs(traindataSliceOutput,mode = 0o666)\n","os.makedirs(trainmaskSliceOutput,mode = 0o666)\n","os.makedirs(testdataSliceOutput,mode = 0o666)\n","os.makedirs(testmaskSliceOutput,mode = 0o666)"]},{"cell_type":"markdown","metadata":{},"source":["Uncomment if more test samples are required. Currently using 2 test, 8 train."]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# move_dir(imageSliceOutput,testdataSliceOutput,'lungs6*.png')\n","# move_dir(imageSliceOutput,testdataSliceOutput,'lungs7*.png')\n","move_dir(imageSliceOutput,testdataSliceOutput,'lungs8*.png')\n","move_dir(imageSliceOutput,testdataSliceOutput,'lungs9*.png')\n","# move_dir(maskSliceOutput,testmaskSliceOutput,'lungs6*.png')\n","# move_dir(maskSliceOutput,testmaskSliceOutput,'lungs7*.png')\n","move_dir(maskSliceOutput,testmaskSliceOutput,'lungs8*.png')\n","move_dir(maskSliceOutput,testmaskSliceOutput,'lungs9*.png')"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["#Move the remaining files into training data folder\n","move_dir(imageSliceOutput,traindataSliceOutput,'*.png')\n","move_dir(maskSliceOutput,trainmaskSliceOutput,'*.png')"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Define constants\n","SEED = 909\n","BATCH_SIZE_TRAIN = 16\n","BATCH_SIZE_TEST = 16\n","\n","IMAGE_HEIGHT = 512\n","IMAGE_WIDTH = 256\n","IMG_SIZE = (IMAGE_HEIGHT, IMAGE_WIDTH)\n","\n","data_dir = './'\n","data_dir_train = os.path.join(data_dir, 'training')\n","# The images should be stored under: \"data/slices/training/img/img\"\n","data_dir_train_image = os.path.join(data_dir_train, 'img')\n","# The images should be stored under: \"data/slices/training/mask/img\"\n","data_dir_train_mask = os.path.join(data_dir_train, 'mask')\n","\n","data_dir_test = os.path.join(data_dir, 'test')\n","# The images should be stored under: \"data/slices/test/img/img\"\n","data_dir_test_image = os.path.join(data_dir_test, 'img')\n","# The images should be stored under: \"data/slices/test/mask/img\"\n","data_dir_test_mask = os.path.join(data_dir_test, 'mask')\n","\n","NUM_TRAIN = len(os.listdir(traindataSliceOutput))\n","NUM_TEST = len(os.listdir(testdataSliceOutput))\n","\n","NUM_OF_EPOCHS = 5"]},{"cell_type":"markdown","metadata":{},"source":["Folder structure organization done! Create Data generators for training."]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["#Uncomment below lines, if Data augmentation during training is required.\n","def create_segmentation_generator_train(img_path, msk_path, BATCH_SIZE):\n","    data_gen_args = dict(rescale=1./255\n","#                      featurewise_center=True,\n","#                      featurewise_std_normalization=True,\n","#                      rotation_range=90\n","#                      width_shift_range=0.2,\n","#                      height_shift_range=0.2,\n","#                      zoom_range=0.3\n","                        )\n","    datagen = ImageDataGenerator(**data_gen_args)\n","    \n","    img_generator = datagen.flow_from_directory(img_path, target_size=IMG_SIZE, class_mode=None, color_mode='grayscale', batch_size=BATCH_SIZE, seed=SEED)\n","    msk_generator = datagen.flow_from_directory(msk_path, target_size=IMG_SIZE, class_mode=None, color_mode='grayscale', batch_size=BATCH_SIZE, seed=SEED)\n","    return zip(img_generator, msk_generator)\n","\n","# Remember not to perform any image augmentation in the test generator!\n","def create_segmentation_generator_test(img_path, msk_path, BATCH_SIZE):\n","    data_gen_args = dict(rescale=1./255)\n","    datagen = ImageDataGenerator(**data_gen_args)\n","    \n","    img_generator = datagen.flow_from_directory(img_path, target_size=IMG_SIZE, class_mode=None, color_mode='grayscale', batch_size=BATCH_SIZE, seed=SEED)\n","    msk_generator = datagen.flow_from_directory(msk_path, target_size=IMG_SIZE, class_mode=None, color_mode='grayscale', batch_size=BATCH_SIZE, seed=SEED)\n","    return zip(img_generator, msk_generator)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["train_generator = create_segmentation_generator_train(data_dir_train_image, data_dir_train_mask, BATCH_SIZE_TRAIN)\n","test_generator = create_segmentation_generator_test(data_dir_test_image, data_dir_test_mask, BATCH_SIZE_TEST)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["#Function to compare between input, mask and prediction\n","def display(display_list):\n","    plt.figure(figsize=(15,15))\n","    \n","    title = ['Input Image', 'True Mask', 'Predicted Mask']\n","    \n","    for i in range(len(display_list)):\n","        plt.subplot(1, len(display_list), i+1)\n","        plt.title(title[i])\n","        plt.imshow(tf.keras.preprocessing.image.array_to_img(display_list[i]), cmap='gray')\n","    plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["#Function to display top n images in datagen\n","def show_dataset(datagen, num=1):\n","    for i in range(0,num):\n","        image,mask = next(datagen)\n","        display([image[0], mask[0]])"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["#Visualize top 3 image comparisons in datagen\n","show_dataset(train_generator, 3)"]},{"cell_type":"markdown","metadata":{},"source":["U-net model development"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def unet(n_levels, initial_features=32, n_blocks=2, kernel_size=3, pooling_size=2, in_channels=1, out_channels=1):\n","    inputs = keras.layers.Input(shape=(IMAGE_HEIGHT, IMAGE_WIDTH, in_channels))\n","    x = inputs\n","    \n","    convpars = dict(kernel_size=kernel_size, activation='relu', padding='same')\n","    \n","    #downstream\n","    skips = {}\n","    for level in range(n_levels):\n","        for _ in range(n_blocks):\n","            x = keras.layers.Conv2D(initial_features * 2 ** level, **convpars)(x)\n","        if level < n_levels - 1:\n","            skips[level] = x\n","            x = keras.layers.MaxPool2D(pooling_size)(x)\n","            \n","    # upstream\n","    for level in reversed(range(n_levels-1)):\n","        x = keras.layers.Conv2DTranspose(initial_features * 2 ** level, strides=pooling_size, **convpars)(x)\n","        x = keras.layers.Concatenate()([x, skips[level]])\n","        for _ in range(n_blocks):\n","            x = keras.layers.Conv2D(initial_features * 2 ** level, **convpars)(x)\n","            \n","    # output\n","    activation = 'sigmoid' if out_channels == 1 else 'softmax'\n","    x = keras.layers.Conv2D(out_channels, kernel_size=1, activation=activation, padding='same')(x)\n","    \n","    return keras.Model(inputs=[inputs], outputs=[x], name=f'UNET-L{n_levels}-F{initial_features}')\n","        "]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["EPOCH_STEP_TRAIN = NUM_TRAIN // BATCH_SIZE_TRAIN\n","EPOCH_STEP_TEST = NUM_TEST // BATCH_SIZE_TEST\n","#Instantiate U-net with 4 levels\n","model = unet(4)\n","model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["model.fit_generator(generator=train_generator, \n","                    steps_per_epoch=EPOCH_STEP_TRAIN, \n","                    validation_data=test_generator, \n","                    validation_steps=EPOCH_STEP_TEST,\n","                   epochs=NUM_OF_EPOCHS)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["model.save(f'UNET-LungSegmentation_{IMAGE_HEIGHT}_{IMAGE_WIDTH}.h5')"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["test_generator = create_segmentation_generator_test(data_dir_test_image, data_dir_test_mask, 1)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def show_prediction(datagen, num=1):\n","    for i in range(0,num):\n","        image,mask = next(datagen)\n","        pred_mask = model.predict(image)[0] > 0.5\n","        display([image[0], mask[0], pred_mask])"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["show_prediction(test_generator, 3)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"}},"nbformat":4,"nbformat_minor":4}
